{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heity94/TWSM_Lab/blob/main/Homework/5_Class_Homework/PH_5_Homework_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "L0HoGesYBC1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "TWSM_path = \"/content/drive/MyDrive/Colab_Notebooks/02_HWR\"\n",
        "\n",
        "#from TWSM import *\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import spacy\n",
        "## Import packages\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# run this from a normal command line\n",
        "#!python -m spacy download en_core_web_md #160MB\n",
        "\n",
        "#can I download this to a local file instead and load it fom drive?\n"
      ],
      "metadata": {
        "id": "4k1Km8WrvyWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f813e48-1ecc-4bcb-f002-70f59bd62899"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whatlies"
      ],
      "metadata": {
        "id": "RaL0PTnTkiWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n",
        "\n",
        "Now, *** restart the colab runtime *** !!"
      ],
      "metadata": {
        "id": "n359prBLepXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word2vec in spacy"
      ],
      "metadata": {
        "id": "sO_IQ0wFdJVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "# Load the spacy model that you have installed\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# process a sentence using the model\n",
        "doc = nlp(\"The sun is shining brightly today but the moon is not\")\n",
        "\n",
        "# It's that simple - all of the vectors and words are assigned after this point\n",
        "# Get the vector for 'text':\n",
        "doc[3].vector\n",
        "\n",
        "# Get the mean vector for the entire sentence (useful for sentence classification etc.)\n",
        "doc.vector"
      ],
      "metadata": {
        "id": "Wxk4NV5AdL04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Opposites are not necessarily different\n",
        "doc = nlp(\"I loved Narnia but hated Armageddon\")\n",
        "\n",
        "print(doc[1])\n",
        "print(doc[4])\n",
        "print(doc[1].similarity(doc[4]))\n",
        "print(doc[4].similarity(doc[1]))\n",
        "\n",
        "doc = nlp(\"The king and the queen are enjoying a sumptious breakfast today\")\n",
        "\n",
        "print(doc[1])\n",
        "print(doc[4])\n",
        "print(doc[1].similarity(doc[4]))\n",
        "print(doc[4].similarity(doc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxqeG5FZfFna",
        "outputId": "25fcd049-48fe-45f6-93d6-40ec2c2ac1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loved\n",
            "hated\n",
            "0.66889775\n",
            "0.66889775\n",
            "king\n",
            "queen\n",
            "0.72526103\n",
            "0.72526103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WhatLies module"
      ],
      "metadata": {
        "id": "HneOrIcxh9z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "king = nlp.vocab[\"king\"].vector\n",
        "man = nlp.vocab[\"man\"].vector\n",
        "queen = nlp.vocab[\"queen\"].vector\n",
        "woman = nlp.vocab[\"woman\"].vector\n",
        "\n",
        "#or:\n",
        "def w2v(w=\"king\"):\n",
        "  return nlp.vocab[w].vector\n",
        "\n",
        "king = w2v(\"king\")"
      ],
      "metadata": {
        "id": "QUURX-boh9A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whatlies import EmbeddingSet\n",
        "from whatlies.language import SpacyLanguage\n",
        "\n",
        "lang = SpacyLanguage('en_core_web_md')\n",
        "words = ['cat', 'dog', 'fish', 'kitten', 'man', 'woman', 'king', 'queen', 'doctor', 'nurse']\n",
        "\n",
        "emb = lang[words]\n",
        "emb.plot_interactive(x_axis='man', y_axis='woman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "KsUIQbjskc_R",
        "outputId": "173048ef-2a0d-4611-e2b5-93064c659ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-a34ef04abf1345bf986ee981c845bb24\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-a34ef04abf1345bf986ee981c845bb24\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-a34ef04abf1345bf986ee981c845bb24\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"field\": \"\", \"legend\": null, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"name\", \"type\": \"nominal\"}, {\"field\": \"original\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"title\": \"man\"}, \"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"woman\"}, \"field\": \"y_axis\", \"type\": \"quantitative\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"man vs. woman\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"field\": \"original\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y_axis\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-9772bd3fc4e5e10fbf898ed48ed7f201\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9772bd3fc4e5e10fbf898ed48ed7f201\": [{\"x_axis\": 0.3758322596549988, \"y_axis\": 0.34616324305534363, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 0.4621913731098175, \"y_axis\": 0.4013059139251709, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 0.350157767534256, \"y_axis\": 0.2681156396865845, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 0.2800500690937042, \"y_axis\": 0.3301210403442383, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": 1.0, \"y_axis\": 0.6816136837005615, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": 0.8037664890289307, \"y_axis\": 1.0, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": 0.45961007475852966, \"y_axis\": 0.27491992712020874, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": 0.2914373576641083, \"y_axis\": 0.40253907442092896, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": 0.4489893317222595, \"y_axis\": 0.4943573474884033, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": 0.3271060585975647, \"y_axis\": 0.5211429595947266, \"name\": \"nurse\", \"original\": \"nurse\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.LayerChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "he4x501G0cdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Algebra**\n",
        "\n",
        "seems much more difficult than in gensim"
      ],
      "metadata": {
        "id": "JQhFmpmee0tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "queries = [w for w in nlp.vocab if w.is_lower and w.prob >= -15]\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    return cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))\n",
        "\n",
        "def most_similar_vec(vec, count=10):\n",
        "    by_similarity = sorted(queries, key=lambda w: cos_sim(w.vector, vec), reverse=True)\n",
        "    return [w.orth_ for w in by_similarity[:count]]\n",
        "\n",
        "vec = nlp('woman').vector + nlp('king').vector - nlp(\"man\").vector\n",
        "most_similar_vec(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Z_BTHmj4G2",
        "outputId": "0b6976f4-4038-4972-f297-e151a19fcda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king',\n",
              " 'queen',\n",
              " 'prince',\n",
              " 'princes',\n",
              " 'kings',\n",
              " 'princess',\n",
              " 'princesses',\n",
              " 'mermaid',\n",
              " 'royal',\n",
              " 'royals']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "id": "S6eNPWlZkDXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## word2vec in gensim"
      ],
      "metadata": {
        "id": "r8MsXo0HgE3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "#https://github.com/RaRe-Technologies/gensim-data\n",
        "wv = api.load('glove-wiki-gigaword-100')#128MB\n",
        "#wv = api.load('glove-wiki-gigaword-50')#65MB\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69CQJjxfgUvR",
        "outputId": "5a5273e2-9ccc-4a61-9319-79f0390d4cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gynWpK0w0eIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    ('car', 'minivan'),   # a minivan is a kind of car\n",
        "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
        "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
        "    ('car', 'cereal'),    # ... and so on\n",
        "    ('car', 'communism'),\n",
        "]\n",
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbLSL0D2g4Je",
        "outputId": "c52c88cd-f71b-43d8-e68a-e2f0c66bad71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'car'\t'minivan'\t0.67\n",
            "'car'\t'bicycle'\t0.69\n",
            "'car'\t'airplane'\t0.65\n",
            "'car'\t'cereal'\t0.12\n",
            "'car'\t'communism'\t0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks\n",
        "\n",
        "1. Train a word2vec model of dimension $100$ on the IMD data. (considering words appearing in more than 50 documents) Save the model if you like.\n",
        "\n",
        "2. Compute the embedding for each review (average word2vec)\n",
        "\n",
        "3. Fit a keras classifier to the embedded reviews. (2 hidden layers of size 40 each) Report/Monitor the accuracy on the test data.\n",
        "\n",
        "4. Load the bing sentiment dictionary. Compute two separate embeddings for the negative and positive sentiments.\n",
        "\n",
        "5. Compute the similarity between these two vectors and a few selected reviews. Does it agree with their label?\n"
      ],
      "metadata": {
        "id": "eA-8MKLQjT1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "YhEZsOc7BVqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMD Movie Reviews**"
      ],
      "metadata": {
        "id": "e3ofzmU3fbUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)"
      ],
      "metadata": {
        "id": "inHlYXX-gCJx",
        "outputId": "6631f821-5879-4ab2-e4f9-e978cc55fcd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoding reviews back to text**"
      ],
      "metadata": {
        "id": "6xrmGZDsPfUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
        "\n",
        "decoded_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "muyre50UtroS",
        "outputId": "92f08891-37a2-4d31-a902-6bea007b0a7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode train data\n",
        "N=len(train_data)\n",
        "decoded_reviews = [\"\" for x in range(N)]\n",
        "\n",
        "for j in range(N):\n",
        "  decoded_reviews[j] = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[j]])\n",
        "  \n",
        "# Get rid of beginning \"?\"\n",
        "decoded_reviews = [review[2:] for review in decoded_reviews]"
      ],
      "metadata": {
        "id": "TnCCq-Dcg4U0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec\n",
        "Train a word2vec model of dimension $100$ on the IMD data. (considering words appearing in more than 50 documents) Save the model if you like."
      ],
      "metadata": {
        "id": "R-Fn0Izm9MW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset for the word2vec model\n",
        "corpus=[doc.split() for doc in decoded_reviews]\n",
        "\n",
        "# Train the model for embeddings of size 100 considering words appearing in more than 50 documents, default window=5\n",
        "model = Word2Vec(corpus, size=100, min_count=50)\n",
        "model.save(TWSM_path+'/00_data/word2vec_imdb.model')"
      ],
      "metadata": {
        "id": "D5MVG4r98lFG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Average word2vec\n",
        "Compute the embedding for each review (average word2vec)"
      ],
      "metadata": {
        "id": "ocalYMLE_Ima"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8OM3aCWvEZC"
      },
      "source": [
        "In the following we will derive the corpus. Note that word2vec (as opposed to doc2vec) generates one embedding for each word in the document. These then need to be aggregated at a document level. The simplest way is to determine the average over all words, but you can also use other aggregators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFBqJ2VS2rYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a59c7c-a3af-4299-c585-79b7c62bbd4b"
      },
      "source": [
        "# Document representation for the text\n",
        "corpus_w2v=[[model.wv[word] for word in doc if word in model.wv.vocab.keys()] for doc in corpus]\n",
        "positive=[i for i in range(len(corpus)) if len(corpus_w2v[i])>0]\n",
        "\n",
        "corpus_w2v2=[corpus_w2v[i] for i in positive]\n",
        "#data_lemma2=[data_lemma[i] for i in positive]\n",
        "\n",
        "# Document average representation\n",
        "corpus_w2v_avg_clean=[sum(words)/len(words) for words in corpus_w2v2]\n",
        "\n",
        "# This corpus can be used later in clustering and classification tasks\n",
        "print(corpus_w2v_avg_clean[10])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.07425238  0.06747388  0.39230126 -0.36663225  0.21546191 -0.36204475\n",
            "  0.07142097  0.07992306  0.03126279 -0.51161313  0.12652317  0.4391952\n",
            " -0.16302423 -0.12542012  0.27796707  0.11315694 -0.1846122   0.07238373\n",
            "  0.45462906  0.01931621  0.1215534   0.03018505 -0.21474141 -0.00561327\n",
            "  0.24638928 -0.15758626 -0.16836031  0.21521203  0.06390181 -0.07232941\n",
            "  0.11160904  0.14934357 -0.30050156  0.19315217  0.30240217  0.12886333\n",
            "  0.15003869  0.05364362  0.10478669  0.14057606  0.18024667 -0.33982483\n",
            "  0.00996698  0.03019215 -0.03181847 -0.38736826 -0.02504646  0.09713174\n",
            "  0.2815634   0.46132156 -0.18515831 -0.38660303 -0.09607214 -0.20545292\n",
            "  0.44870573 -0.02355427  0.39900258 -0.41577318 -0.2690298  -0.14373663\n",
            "  0.03981441 -0.06252696 -0.4330292  -0.21920864 -0.24917193  0.06513843\n",
            "  0.6396006   0.5933016   0.10797528 -0.08458997 -0.09392422 -0.44205388\n",
            " -0.33044085  0.00815693  0.00944452 -0.29033545 -0.21981075 -0.16393258\n",
            " -0.42866853  0.1167855   0.02380345 -0.19003735  0.06491923 -0.37294996\n",
            " -0.45045215 -0.14345226 -0.25404736 -0.2555466  -0.07514463 -0.18100905\n",
            " -0.12672105  0.06775453 -0.00091381  0.07769222  0.01155721 -0.17561737\n",
            " -0.45145223 -0.23141432 -0.06667303  0.28540736]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Classifier\n",
        "Fit a keras classifier to the embedded reviews. (2 hidden layers of size 40 each) Report/Monitor the accuracy on the test data."
      ],
      "metadata": {
        "id": "Nu46w0LU8paj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the architecture\n",
        "clf = keras.Sequential()\n",
        "clf.add(layers.Dense(40, input_dim=100, activation='relu')) \n",
        "clf.add(layers.Dense(40, activation='relu'))\n",
        "clf.add(layers.Dense(1, activation='sigmoid')) "
      ],
      "metadata": {
        "id": "rpWlgsOjA8Mq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Complile\n",
        "clf.compile(optimizer='adam',\n",
        "    loss='binary_crossentropy', \n",
        "    metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "0BVx1BrWDIbv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Early stopping\n",
        "es = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "kLYhZPOrRI8e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit\n",
        "clf.fit(np.array(corpus_w2v_avg_clean), train_labels, epochs=100, validation_split=0.3, callbacks=[es])"
      ],
      "metadata": {
        "id": "w5QE8xD0DQIv",
        "outputId": "134b636a-9411-4172-c35f-409d5f074b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "547/547 [==============================] - 2s 3ms/step - loss: 0.4607 - accuracy: 0.7850 - val_loss: 0.3850 - val_accuracy: 0.8307\n",
            "Epoch 2/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3891 - accuracy: 0.8274 - val_loss: 0.3707 - val_accuracy: 0.8392\n",
            "Epoch 3/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3794 - accuracy: 0.8327 - val_loss: 0.3707 - val_accuracy: 0.8344\n",
            "Epoch 4/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3767 - accuracy: 0.8332 - val_loss: 0.3887 - val_accuracy: 0.8236\n",
            "Epoch 5/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3744 - accuracy: 0.8348 - val_loss: 0.3827 - val_accuracy: 0.8312\n",
            "Epoch 6/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8370 - val_loss: 0.3897 - val_accuracy: 0.8279\n",
            "Epoch 7/100\n",
            "547/547 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8387 - val_loss: 0.3644 - val_accuracy: 0.8419\n",
            "Epoch 8/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3616 - accuracy: 0.8389 - val_loss: 0.3634 - val_accuracy: 0.8388\n",
            "Epoch 9/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3594 - accuracy: 0.8447 - val_loss: 0.3622 - val_accuracy: 0.8401\n",
            "Epoch 10/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.8429 - val_loss: 0.3631 - val_accuracy: 0.8408\n",
            "Epoch 11/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8433 - val_loss: 0.3689 - val_accuracy: 0.8395\n",
            "Epoch 12/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3499 - accuracy: 0.8459 - val_loss: 0.3647 - val_accuracy: 0.8391\n",
            "Epoch 13/100\n",
            "547/547 [==============================] - 2s 3ms/step - loss: 0.3496 - accuracy: 0.8463 - val_loss: 0.3623 - val_accuracy: 0.8392\n",
            "Epoch 14/100\n",
            "547/547 [==============================] - 2s 4ms/step - loss: 0.3455 - accuracy: 0.8478 - val_loss: 0.3815 - val_accuracy: 0.8295\n",
            "Epoch 15/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.8501 - val_loss: 0.3724 - val_accuracy: 0.8389\n",
            "Epoch 16/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8492 - val_loss: 0.3629 - val_accuracy: 0.8384\n",
            "Epoch 17/100\n",
            "547/547 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8499 - val_loss: 0.3743 - val_accuracy: 0.8377\n",
            "Epoch 18/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8525 - val_loss: 0.3558 - val_accuracy: 0.8461\n",
            "Epoch 19/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8555 - val_loss: 0.3611 - val_accuracy: 0.8429\n",
            "Epoch 20/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8550 - val_loss: 0.3816 - val_accuracy: 0.8297\n",
            "Epoch 21/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8570 - val_loss: 0.3604 - val_accuracy: 0.8467\n",
            "Epoch 22/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8593 - val_loss: 0.3641 - val_accuracy: 0.8461\n",
            "Epoch 23/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8603 - val_loss: 0.3758 - val_accuracy: 0.8349\n",
            "Epoch 24/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.8593 - val_loss: 0.3604 - val_accuracy: 0.8455\n",
            "Epoch 25/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8616 - val_loss: 0.3652 - val_accuracy: 0.8397\n",
            "Epoch 26/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.8615 - val_loss: 0.3697 - val_accuracy: 0.8396\n",
            "Epoch 27/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.8637 - val_loss: 0.3686 - val_accuracy: 0.8389\n",
            "Epoch 28/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8650 - val_loss: 0.3695 - val_accuracy: 0.8393\n",
            "Epoch 29/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.8660 - val_loss: 0.3712 - val_accuracy: 0.8393\n",
            "Epoch 30/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3100 - accuracy: 0.8663 - val_loss: 0.3935 - val_accuracy: 0.8281\n",
            "Epoch 31/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8661 - val_loss: 0.3716 - val_accuracy: 0.8440\n",
            "Epoch 32/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8673 - val_loss: 0.3728 - val_accuracy: 0.8385\n",
            "Epoch 33/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8702 - val_loss: 0.3787 - val_accuracy: 0.8415\n",
            "Epoch 34/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3016 - accuracy: 0.8694 - val_loss: 0.3783 - val_accuracy: 0.8408\n",
            "Epoch 35/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.3027 - accuracy: 0.8681 - val_loss: 0.3864 - val_accuracy: 0.8363\n",
            "Epoch 36/100\n",
            "547/547 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8713 - val_loss: 0.3850 - val_accuracy: 0.8425\n",
            "Epoch 37/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.8737 - val_loss: 0.3861 - val_accuracy: 0.8340\n",
            "Epoch 38/100\n",
            "547/547 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.8734 - val_loss: 0.3864 - val_accuracy: 0.8412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff733e90310>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode test data\n",
        "N=len(test_data)\n",
        "decoded_reviews_test = [\"\" for x in range(N)]\n",
        "\n",
        "for j in range(N):\n",
        "  decoded_reviews_test[j] = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in test_data[j]])\n",
        "  \n",
        "# Get rid of beginning \"?\"\n",
        "decoded_reviews_test = [review[2:] for review in decoded_reviews_test]\n",
        "\n",
        "# Prepare the dataset for the word2vec model\n",
        "corpus_test=[doc.split() for doc in decoded_reviews_test]\n",
        "\n",
        "# Document representation for the text\n",
        "corpus_w2v_test=[[model.wv[word] for word in doc if word in model.wv.vocab.keys()] for doc in corpus_test]\n",
        "positive_test=[i for i in range(len(corpus_test)) if len(corpus_w2v_test[i])>0]\n",
        "\n",
        "corpus_w2v2_test=[corpus_w2v_test[i] for i in positive_test]\n",
        "#data_lemma2=[data_lemma[i] for i in positive]\n",
        "\n",
        "# Document average representation\n",
        "corpus_w2v_avg_clean_test=[sum(words)/len(words) for words in corpus_w2v2_test]"
      ],
      "metadata": {
        "id": "dK1Fwwx8V3yW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check shape\n",
        "np.array(corpus_w2v_avg_clean_test).shape"
      ],
      "metadata": {
        "id": "wLDnUjBjWeph",
        "outputId": "94fe01e2-9ff2-40ef-b6b2-1ab1c9fc3e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = clf.evaluate(np.array(corpus_w2v_avg_clean_test), test_labels, verbose=0)\n",
        "print(\"Accuracy on test_data:\", np.round(results[1],2))"
      ],
      "metadata": {
        "id": "2l9muBoOWz9J",
        "outputId": "a40e492d-ad0b-40ca-96c1-5733a8d584ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test_data: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bing sentiment embeddings\n",
        "Load the bing sentiment dictionary. Compute two separate embeddings for the negative and positive sentiments."
      ],
      "metadata": {
        "id": "zK0lTWmdAKDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ojfbavFUA8xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity between positive and negative embeddings\n",
        "Compute the similarity between these two vectors and a few selected reviews. Does it agree with their label?\n"
      ],
      "metadata": {
        "id": "P3_VlbebAh3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YDD-VxWRAqb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Class5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}